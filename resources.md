---
layout: page
title: AI Safety Resources
permalink: /resources/
---

## Commitments
* [Frontier AI Safety Commitments](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024).

## Published Company Policies
* Anthropic: [Responsible Scaling Policy](https://www.anthropic.com/responsible-scaling-policy)
* OpenAI: [Preparedness Framework](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf)
* Google DeepMind: [Frontier Safety Framework](https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/updating-the-frontier-safety-framework/Frontier%20Safety%20Framework%202.0%20(1).pdf)
* Magic: [AGI Readiness Policy](https://magic.dev/agi-readiness-policy)
* NAVER: [AI Safety Framework](https://clova.ai/en/tech-blog/en-navers-ai-safety-framework-asf)
* Meta: [Frontier AI Framework](https://ai.meta.com/static-resource/meta-frontier-ai-framework/)
* G42: [Frontier AI Safety Framework](https://www.g42.ai/application/files/9517/3882/2182/G42_Frontier_Safety_Framework_Publication_Version.pdf)
* Cohere: [Secure AI Frontier Model Framework](https://cohere.com/security/the-cohere-secure-ai-frontier-model-framework-february-2025.pdf)
* Microsoft: [Frontier Governance Framework](https://go.microsoft.com/fwlink/?linkid=2303737&clcid=0x409&culture=en-us&country=us)
* Amazon: [Frontier Model Safety Framework](https://www.amazon.science/publications/amazons-frontier-model-safety-framework)
* xAI: [Risk Management Framework (Draft)](https://x.ai/documents/2025.02.20-RMF-Draft.pdf)
* Nvidia: [Frontier AI Risk Assessment](https://images.nvidia.com/content/pdf/NVIDIA-Frontier-AI-Risk-Assessment.pdf)


## Papers
* [Emerging Practices in Frontier AI Safety Frameworks](https://arxiv.org/abs/2503.04746)

## Relevent Entities
* [The Center for AI Safety](https://safe.ai/)
* [Model Evaluation & Threat Research](https://metr.org/)
* [The AI Security Institute](https://www.aisi.gov.uk/)

## Other Resources
* [Trustworthy ML Initiative](https://www.trustworthyml.org/)
